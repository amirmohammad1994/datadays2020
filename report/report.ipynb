{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"section1\"   dir='rtl'>\n",
    "<h1>\n",
    "    عنوان؟؟؟؟\n",
    "    </h1>\n",
    "        <hr>\n",
    "        \n",
    "       توضیحات؟؟؟؟\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_uf = pd.read_csv('user_feature.cvs')\n",
    "\n",
    "df_new_uf = df_uf.drop(columns = ['Unnamed: 0','VC','visit_number'])\n",
    "del(df_uf)\n",
    "\n",
    "arr = pd.DataFrame(df_new_uf['topicId'].drop_duplicates()).reset_index()\n",
    "#arr.info()\n",
    "\n",
    "arr['index'] = arr['topicId']\n",
    "arr['topicId'] = arr['topicId'].astype('object')\n",
    "#arr.info()\n",
    "\n",
    "df_inx = pd.get_dummies(arr)\n",
    "del(arr)\n",
    "\n",
    "df_inx.rename(columns = {'index':'topicId'}, inplace = True)\n",
    "\n",
    "df_new_uf['like_point'] = df_new_uf['like_point'] * 100\n",
    "df_new_uf['like_point'] = df_new_uf['like_point'].astype('unit8')\n",
    "\n",
    "df_uf = pd.merge(df_new_uf, df_inx, how = 'inner', on = 'topicId')\n",
    "df_uf.head()\n",
    "\n",
    "del(df_new_uf)\n",
    "\n",
    "for i in range(3,53):\n",
    "    df_uf.iloc[:,i] = df_uf.iloc[:,i] * df_uf['like_point']\n",
    "df_uf.info()\n",
    "\n",
    "df_user_feature = df_uf.groupby(['userId'])[df_uf.filter(regex='topicId_.*').columns].sum()\n",
    "#df_user_feature.info()\n",
    "#df_user_feature.head(20)\n",
    "\n",
    "df_user_feature.to_csv('user_like.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"section1\"   dir='rtl'>\n",
    "<h1>\n",
    "    خوشه بندی کاربرها\n",
    "    </h1>\n",
    "        <hr>\n",
    "        در این مرحله با استفاده از جدول\n",
    "    user_like.csv\n",
    "    که در مراحل قبل به دست آوردیم، کاربرها را خوشه‌بندی می‌کنیم و نهایتا خروجی کد را در فایل\n",
    "    user_cluster می‌ریزیم.\n",
    "        <br>\n",
    "        کد زیر این کار را انجام میدهد:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df_user_feature = pd.read_csv('user_like.csv')\n",
    "\n",
    "X = df_user_feature.iloc[:, 1:53].values\n",
    "kmeans = KMeans(n_clusters=28, init='k-means++', max_iter=500, n_init=10)\n",
    "pred_y = kmeans.fit_predict(X)\n",
    "df_user_feature['Cluster'] = pred_y\n",
    "\n",
    "df_user_cluster = df_user_cluster.set_index('userId')\n",
    "df_user_cluster.to_csv('user_cluster.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"section1\"   dir='rtl'>\n",
    "<h1>\n",
    "    خوشه بندی تبلیغ‌ها\n",
    "    </h1>\n",
    "        <hr>\n",
    "        در این مرحله با استفاده از جدول\n",
    "    ad_title.csv\n",
    "    قصد داریم تبلیغ‌ها را بر اساس تعداد کلمات مشترک به کار رفته در آن‌ها خوشه‌بندی کنیم.\n",
    "    <br>\n",
    "    برای این کار جدولی ساخته می‌شود که سطرهای آن شناسه هر تبلیغ، و ستون‌های آن هرکدام بیانگر یک کلمه یکتا هستند. در این جدول برای هر شناسه تبلیغ در سطر نظیر آن، مقادیر ستون‌های متناظر با کلمات به کار رفته در تبلیغ را برابر با یک قرار می‌دهیم. و باقی خانه‌های جدول مقدار صفر می‌گیرند.\n",
    "    <br>\n",
    "    دقت کنید که هر سطر به معنای یک بردار با مقادیر صفر و یک است، و برای هر دو تبلیغ اختلاف دو بردار نظیرشان بیانگر فاصله آن دو تبلیغ است.\n",
    "        <br>\n",
    "        کد زیر این کار را انجام میدهد:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_ad_t = pd.read_csv('ad_title.csv')\n",
    "\n",
    "arr = pd.DataFrame(df_ad_t['wordId'])\n",
    "arr = arr.drop_duplicates().reset_index()\n",
    "#print(arr)\n",
    "\n",
    "arr['index'] = arr['wordId']\n",
    "arr['wordId'] = arr['wordId'].astype('object')\n",
    "#print(arr)\n",
    "\n",
    "df_inx = pd.get_dummies(arr)\n",
    "#df_inx.head(10)\n",
    "\n",
    "df_inx.rename(columns={'index':'wordId'}, inplace = True)\n",
    "#df_inx.head(10)\n",
    "\n",
    "df_ad_title = pd.merge(df_ad_t, df_inx, how = 'inner', on = 'wordId')\n",
    "#df_ad_title.info()\n",
    "\n",
    "df_ad_title = df_ad_title.drop(['wordId'], axis=1)\n",
    "df_ad_title = df_ad_title.groupby(['adId'])[df_ad_title.filter(regex='wordId_.*').columns].sum()\n",
    "df_ad_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    حال به خوشه‌بندی تبلیغ‌ها بر اساس فاصله‌ای که در بالا تعریف کردیم می‌پردازیم:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_ad_title.iloc[:, 1:2109].values\n",
    "kmeans = KMeans(n_clusters=120, init='k-means++', max_iter=500, n_init=10)\n",
    "pred_y = kmeans.fit_predict(X)\n",
    "df_ad_title['Cluster'] = pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    در نهایت خروجی کد در فایل \n",
    "    ad_cluster.csv\n",
    "    ریخته می‌شود و در مراحل بعدی مورد استفاده قرار می‌گیرد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ad_cluster = df_ad_title.filter(['adId','Cluster'], axis=1)\n",
    "df_ad_cluster.to_csv('ad_cluster.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"section1\"   dir='rtl'>\n",
    "<h1>\n",
    "    فاز تصمیم گیری\n",
    "    </h1>\n",
    "        <hr>\n",
    "        با فرض اینکه برای تبلیغات و کاربر ها بر حسب شناسه اشان خوشه بندی در فایل های \n",
    "        ad_cluster.csv , user_cluster.csv\n",
    "        داریم، ابتدا به ساخت فایل\n",
    "        view_cluster.csv\n",
    "        می پردازیم که که می گوید هر خوشه از یوز ها هر خوشه از تبیلغ ها را چند بار کلیک کرده است.\n",
    "        <br>\n",
    "        کد زیر این کار را انجام میدهد:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pycodes/cluster_view.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "users = {-1}\n",
    "\n",
    "def displayId_to_userId(displayId):\n",
    "    return display_to_user[displayId]\n",
    "\n",
    "def userId_to_cluster(userId):\n",
    "    if (userId in user_to_cluster):\n",
    "        return user_to_cluster[userId]\n",
    "    else:\n",
    "        users.add(userId)\n",
    "        return 28\n",
    "\n",
    "def addId_to_cluster(adId):\n",
    "    if (adId in ad_to_cluster):\n",
    "        return ad_to_cluster[adId]\n",
    "    else:\n",
    "        return 120\n",
    "\n",
    "events_df = pd.read_csv('event.csv',skipinitialspace=True, usecols=[\"displayId\",\"userId\"])\n",
    "display_to_user = dict(zip(events_df.displayId, events_df.userId))\n",
    "\n",
    "user_clusters_df = pd.read_csv('user_cluster.csv')\n",
    "user_to_cluster = dict(zip(user_clusters_df.userId, user_clusters_df.Cluster))\n",
    "\n",
    "ad_clusters_df = pd.read_csv('ad_cluster.csv')\n",
    "ad_to_cluster = dict(zip(ad_clusters_df.adId, ad_clusters_df.Cluster))\n",
    "\n",
    "click_train_df = pd.read_csv('click_train.csv')\n",
    "click_train_df = click_train_df[click_train_df['clicked']==1]\n",
    "#print(click_train_df.head())\n",
    "click_train_df['adCluster'] = click_train_df['adId'].map(addId_to_cluster)\n",
    "click_train_df['userCluster'] = click_train_df['displayId'].map(displayId_to_userId).map(userId_to_cluster)\n",
    "#print(click_train_df.head())\n",
    "matrix_1 = pd.crosstab(click_train_df['userCluster'],click_train_df['adCluster'])\n",
    "#print(matrix_1.head())\n",
    "#print(matrix_1.info())\n",
    "\n",
    "click_train_df = pd.read_csv('click_train.csv')\n",
    "click_train_df = click_train_df[click_train_df['clicked']==0]\n",
    "#print(click_train_df.head())\n",
    "click_train_df['adCluster'] = click_train_df['adId'].map(addId_to_cluster)\n",
    "click_train_df['userCluster'] = click_train_df['displayId'].map(displayId_to_userId).map(userId_to_cluster)\n",
    "#print(click_train_df.head())\n",
    "matrix_2 = pd.crosstab(click_train_df['userCluster'],click_train_df['adCluster'])\n",
    "#print(matrix_2.head())\n",
    "#print(matrix_2.info())\n",
    "\n",
    "matrix = matrix_2*-1 + matrix_1*10\n",
    "\n",
    "#print(matrix.head())\n",
    "#print(matrix.info())\n",
    "\n",
    "matrix.to_csv('view_cluster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    دقت کنید فقط تبلیغات کلیک شده مدنظرند و ماتریس فوق نشان می دهد یوزر هایی که در کلاستر \n",
    "    i\n",
    "    ام بوده اند چند بار تبلیغی از کلاستر \n",
    "    j\n",
    "    ام را دیده اند. یعنی به هر بازدید وزن مثبت یک داده ایم به طور مشابه برای کلیک نکردن هم به هر کدام وزن -۰.۱ میدهیم و به جدول فوق اضافه می کنیم.\n",
    "    <br>\n",
    "    دقت کنید اطلاعت فوق از \n",
    "    click_train.csv\n",
    "    به دست می آید و ما با جوین کردن با\n",
    "    event.csv\n",
    "    و اطلاعات کلاستر ها از\n",
    "    user_cluster.csv , ad_cluster.csv\n",
    "    اطلاعات فوق را استخراج می کنیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pycodes/algorithm1.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def displayId_to_userId(displayId):\n",
    "    return display_to_user[displayId]\n",
    "\n",
    "def userId_to_cluster(userId):\n",
    "    if (userId in user_to_cluster):\n",
    "        return user_to_cluster[userId]\n",
    "    else:\n",
    "        return 28\n",
    "def addId_to_cluster(adId):\n",
    "    if (adId in ad_to_cluster):\n",
    "        return ad_to_cluster[adId]\n",
    "    else:\n",
    "        return 120\n",
    "\n",
    "\n",
    "def userCluster_addCluster_matrix(userCluster,adCluster):\n",
    "    result = np.random.randint(10,size=len(adCluster))\n",
    "    for i in range(len(adCluster)):\n",
    "        try:\n",
    "            result[i] = view_df[str(adCluster[i])][userCluster]\n",
    "        except KeyError:\n",
    "            result[i] = np.random.randint(1000)\n",
    "    return result\n",
    "\n",
    "def get_rank_array(array,keys):\n",
    "    array2 = array[:]\n",
    "    array2.sort(reverse=True)\n",
    "    result = {}\n",
    "    for i in range(len(array)):\n",
    "        result[str(array2[i])] = i+1\n",
    "    return result\n",
    "\n",
    "def rank_simple(vector):\n",
    "    return sorted(range(len(vector)), reverse=True,key=vector.__getitem__)\n",
    "\n",
    "events_df = pd.read_csv('../event.csv',skipinitialspace=True, usecols=[\"displayId\",\"userId\"])\n",
    "display_to_user = dict(zip(events_df.displayId, events_df.userId))\n",
    "\n",
    "user_clusters_df = pd.read_csv('../user_cluster.csv')\n",
    "user_to_cluster = dict(zip(user_clusters_df.userId, user_clusters_df.Cluster))\n",
    "\n",
    "ad_clusters_df = pd.read_csv('../ad_cluster.csv')\n",
    "ad_to_cluster = dict(zip(ad_clusters_df.adId, ad_clusters_df.Cluster))\n",
    "\n",
    "view_df = pd.read_csv('../view_cluster.csv')\n",
    "\n",
    "test_df = pd.read_csv('../click_test.csv')\n",
    "test_df['adIdCluster'] = test_df['adId'].map(addId_to_cluster)\n",
    "num_of_slots = test_df.groupby(['displayId']).apply(lambda f: len(f['displayId']))\n",
    "ads_df = test_df.groupby(['displayId'])['adIdCluster'].apply(lambda group_series: group_series.tolist()).reset_index(name=\"adsCluster\")\n",
    "ads_df2 = test_df.groupby(['displayId'])['adId'].apply(lambda group_series: group_series.tolist()).reset_index(name=\"ads\")\n",
    "ads_df = ads_df.merge(ads_df2)\n",
    "ads_df['userCluster'] = ads_df['displayId'].map(displayId_to_userId).map(userId_to_cluster)\n",
    "ads_df['adsPoints'] = ads_df.apply(lambda x: userCluster_addCluster_matrix(userCluster = x['userCluster'], adCluster = x['adsCluster']), axis=1)\n",
    "print(ads_df.head())\n",
    "print(ads_df[2:][:].head())\n",
    "print(view_df.head())\n",
    "result_adId = []\n",
    "result_displayId = []\n",
    "result_rank = []\n",
    "for idx,row in ads_df.iterrows():\n",
    "    ranks = rank_simple(row['adsPoints'].tolist())\n",
    "    for i in range(len(row['ads'])):\n",
    "        result_adId.append(row['ads'][i])\n",
    "        result_displayId.append(row['displayId'])\n",
    "        result_rank.append(ranks[i]+1)\n",
    "\n",
    "result_df = pd.DataFrame({\"displayId\" : result_displayId, \"adId\" : result_adId , \"rank\": result_rank})\n",
    "print(result_df.head())\n",
    "result_df.to_csv('results2.csv',header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    کد فوق خروجی نهایی کار را در \n",
    "    result2.csv\n",
    "    می ریزد.\n",
    "    <br>\n",
    "    برای هر چهارچوب نمایش ما باید رتبه بندی بین تبلیغ های ارائه شده بدهیم که در ماتریسی که در مرحله قبل ساخته شد هر کدام از این تبلیغ ها برای این یوزر توجه کنید که ابتدا همه تبلیغ ها و یوزر را به کلاسترشان مپ می کنیم ، امتیازی دارد و ما بر حسب همین امتیاز ها به تبیلغ ها رتبه می دهیم.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
